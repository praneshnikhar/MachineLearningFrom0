{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d48d6af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in ./.venv/lib/python3.13/site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.venv/lib/python3.13/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.13/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./.venv/lib/python3.13/site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.venv/lib/python3.13/site-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in ./.venv/lib/python3.13/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib/python3.13/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in ./.venv/lib/python3.13/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in ./.venv/lib/python3.13/site-packages (from tensorflow) (6.33.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.venv/lib/python3.13/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.13/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.13/site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in ./.venv/lib/python3.13/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.venv/lib/python3.13/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.13/site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in ./.venv/lib/python3.13/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in ./.venv/lib/python3.13/site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.13/site-packages (from tensorflow) (2.3.5)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./.venv/lib/python3.13/site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in ./.venv/lib/python3.13/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: pillow in ./.venv/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in ./.venv/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in ./.venv/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in ./.venv/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in ./.venv/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1951858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fc5ef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 784).astype(\"float32\") / 255.0\n",
    "x_test  = x_test.reshape(-1, 784).astype(\"float32\") / 255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06185769",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test  = tf.keras.utils.to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e375b984",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "tf = tf.compat.v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47e09614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(input_, weight_shape, bias_shape, phase_train):\n",
    "    weight_init = tf.random_normal_initializer(stddev=(1.0 / weight_shape[0])**0.5)\n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "\n",
    "    W = tf.get_variable(\"W\", weight_shape, initializer=weight_init)\n",
    "    b = tf.get_variable(\"b\", bias_shape, initializer=bias_init)\n",
    "\n",
    "    logits = tf.matmul(input_, W) + b\n",
    "    return tf.nn.sigmoid(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "446bbf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x, n_code, phase_train):\n",
    "    with tf.variable_scope(\"encoder\"):\n",
    "        with tf.variable_scope(\"layer1\"):\n",
    "            h1 = layer(x, [784, 256], [256], phase_train)\n",
    "\n",
    "        with tf.variable_scope(\"layer2\"):\n",
    "            h2 = layer(h1, [256, 128], [128], phase_train)\n",
    "\n",
    "        with tf.variable_scope(\"code\"):\n",
    "            code = layer(h2, [128, n_code], [n_code], phase_train)\n",
    "\n",
    "    return code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b363a8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(code, n_code, phase_train):\n",
    "    with tf.variable_scope(\"decoder\"):\n",
    "        with tf.variable_scope(\"hidden_1\"):\n",
    "            l1 = layer(code, [n_code, 128], [128], phase_train)\n",
    "        with tf.variable_scope(\"hidden_2\"):\n",
    "            l2 = layer(l1, [128, 256], [256], phase_train)\n",
    "        with tf.variable_scope(\"output\"):\n",
    "            output = layer(l2, [256, 784], [784], phase_train)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "11de2192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(output, x):\n",
    "    with tf.variable_scope(\"training\"):\n",
    "        l2 = tf.sqrt(tf.reduce_sum(tf.square(output - x), axis=1))\n",
    "        train_loss = tf.reduce_mean(l2)\n",
    "        tf.summary.scalar(\"train_cost\", train_loss)\n",
    "    return train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d74195bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(cost):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(cost)\n",
    "    return train_op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "72f29fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_summary(label, tensor):\n",
    "    reshaped = tf.reshape(tensor, [-1, 28, 28, 1])\n",
    "    return tf.summary.image(label, reshaped, max_outputs=4)\n",
    "\n",
    "def evaluate(output, x):\n",
    "    with tf.variable_scope(\"validation\"):\n",
    "        in_img = image_summary(\"input_image\", x)\n",
    "        out_img = image_summary(\"output_image\", output)\n",
    "\n",
    "        l2 = tf.sqrt(tf.reduce_sum(tf.square(output - x), axis=1))\n",
    "        val_loss = tf.reduce_mean(l2)\n",
    "\n",
    "        tf.summary.scalar(\"val_cost\", val_loss)\n",
    "    return val_loss, in_img, out_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e3a0dc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf = tf.compat.v1\n",
    "\n",
    "n_code = 32  # latent space size\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.variable_scope(\"autoencoder_model\"):\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    phase_train = tf.placeholder(tf.bool)\n",
    "\n",
    "    code = encoder(x, n_code, phase_train)\n",
    "    output = decoder(code, n_code, phase_train)\n",
    "\n",
    "    cost = loss_fn(output, x)\n",
    "    train_op = training(cost)\n",
    "\n",
    "    val_loss, in_img, out_img = evaluate(output, x)\n",
    "\n",
    "summary_op = tf.summary.merge_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b8d29d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(output, x):\n",
    "    with tf.variable_scope(\"validation\"):\n",
    "        in_img = image_summary(\"input_image\", x)\n",
    "        out_img = image_summary(\"output_image\", output)\n",
    "\n",
    "        l2 = tf.sqrt(tf.reduce_sum(tf.square(output - x), axis=1))\n",
    "        val_loss = tf.reduce_mean(l2)\n",
    "        tf.summary.scalar(\"val_loss\", val_loss)\n",
    "\n",
    "    return val_loss, in_img, out_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb54a377",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_code = 32\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.variable_scope(\"autoencoder_model\"):\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    phase_train = tf.placeholder(tf.bool)\n",
    "\n",
    "    code = encoder(x, n_code, phase_train)\n",
    "    output = decoder(code, n_code, phase_train)\n",
    "\n",
    "    loss = loss_fn(output, x)\n",
    "    train_op = training(loss)\n",
    "\n",
    "    val_loss, in_img, out_img = evaluate(output, x)\n",
    "\n",
    "summary_op = tf.summary.merge_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1005f18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1769768941.199242  463607 mlir_graph_optimization_pass.cc:437] MLIR V1 optimization pass is not enabled\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "logdir = \"logs/autoencoder\"\n",
    "os.makedirs(logdir, exist_ok=True)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "train_writer = tf.summary.FileWriter(logdir + \"/train\", sess.graph)\n",
    "val_writer = tf.summary.FileWriter(logdir + \"/val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0dae28c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m      5\u001b[39m     avg_loss = \u001b[32m0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     total_batch = \u001b[38;5;28mint\u001b[39m(\u001b[43mmnist\u001b[49m.train.num_examples / batch_size)\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(total_batch):\n\u001b[32m      9\u001b[39m         batch_x, _ = mnist.train.next_batch(batch_size)\n",
      "\u001b[31mNameError\u001b[39m: name 'mnist' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_loss = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_x, _ = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        _, l, summary = sess.run(\n",
    "            [train_op, loss, summary_op],\n",
    "            feed_dict={x: batch_x, phase_train: True}\n",
    "        )\n",
    "\n",
    "        train_writer.add_summary(summary, epoch * total_batch + i)\n",
    "        avg_loss += l / total_batch\n",
    "\n",
    "    v_loss, v_summary = sess.run(\n",
    "        [val_loss, summary_op],\n",
    "        feed_dict={x: mnist.validation.images, phase_train: False}\n",
    "    )\n",
    "\n",
    "    val_writer.add_summary(v_summary, epoch)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {avg_loss:.4f}, Val Loss: {v_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "741221c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.examples'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexamples\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtutorials\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmnist\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m input_data\n\u001b[32m      2\u001b[39m mnist = input_data.read_data_sets(\u001b[33m\"\u001b[39m\u001b[33mdata/\u001b[39m\u001b[33m\"\u001b[39m, one_hot=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow.examples'"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d97cae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
